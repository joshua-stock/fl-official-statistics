{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshua-stock/fl-official-statistics/blob/main/med-insurance/fl-tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB5xVEFddDNc"
      },
      "source": [
        "# Hands-on introduction to Federated Learning for tabular data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTj_zg2rdax8"
      },
      "source": [
        "### Cf. Tensorflow Federated Tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJsx32fNdQV1"
      },
      "source": [
        "**Getting started**\n",
        "\n",
        "1. [Federated Learning for image classification](https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification)\n",
        "1. [Federated Learning for Text Generation](https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation)\n",
        "1. [Tuning recommended aggregations for learning](https://www.tensorflow.org/federated/tutorials/tuning_recommended_aggregators)\n",
        "1. [Federated Reconstruction for Matrix Factorization](https://www.tensorflow.org/federated/tutorials/federated_reconstruction_for_matrix_factorization)\n",
        "\n",
        "**... and  [more](https://www.tensorflow.org/federated/tutorials/tutorials_overview)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFexQMModRkl"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExKgmteFcs5R",
        "outputId": "00180795-f67a-4ba5-ab9e-e534f3e90460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COLAB? False\n"
          ]
        }
      ],
      "source": [
        "# Setup colab if needed\n",
        "\n",
        "import os\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "print(\"COLAB? {}\".format(IN_COLAB))\n",
        "\n",
        "if IN_COLAB:\n",
        "\n",
        "    # rm repo from gdrive\n",
        "    if os.path.exists(\"fl-official-statistics\"):\n",
        "      %rm -r fl-official-statistics\n",
        "\n",
        "    # clone\n",
        "    !git clone https://github.com/joshua-stock/fl-official-statistics\n",
        "    %cd fl-official-statistics\n",
        "\n",
        "    # pull (the currenct version of the repo)\n",
        "    !git pull\n",
        "\n",
        "    !pip install -q tensorflow-federated==0.56.0\n",
        "    # or possibly !pip install -r requirements.txt\n",
        "\n",
        "    os.chdir(\"med-insurance\")\n",
        "    \n",
        "\n",
        "# suppress tf debug logging\n",
        "# =========================\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "#0 = all messages are logged (default behavior)\n",
        "#1 = INFO messages are not printed\n",
        "#2 = INFO and WARNING messages are not printed\n",
        "#3 = INFO, WARNING, and ERROR messages are not printed\n",
        "\n",
        "# S. https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data (medical insurance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.321227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.479150</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.458434</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.326087</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.181464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.347592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age  sex       bmi  children  smoker     region      charges\n",
              "0  0.021739  0.0  0.321227       0.0     1.0  southwest  16884.92400\n",
              "1  0.000000  1.0  0.479150       0.2     0.0  southeast   1725.55230\n",
              "2  0.217391  1.0  0.458434       0.6     0.0  southeast   4449.46200\n",
              "3  0.326087  1.0  0.181464       0.0     0.0  northwest  21984.47061\n",
              "4  0.304348  1.0  0.347592       0.0     0.0  northwest   3866.85520"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
        "\n",
        "client_var = 'region'   # variable, used to split clients\n",
        "target     = 'charges'  # target of the estimation\n",
        "\n",
        "df_raw  = pd.read_csv('data/insurance.csv')\n",
        "\n",
        "# preprocessing\n",
        "df = df_raw.copy()\n",
        "\n",
        "df[['sex', 'smoker']] = OrdinalEncoder(\n",
        "  ).fit_transform(df[['sex', 'smoker']].astype('category'))\n",
        "df[['age', 'bmi', 'children']] = MinMaxScaler(\n",
        "  ).fit_transform(df[['age', 'bmi', 'children']])\n",
        "\n",
        "clients = df[client_var].unique() # define the clients.\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Minimal example (no custom wrapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following script takes as input data, a model architecture and some training specifics and applies Federated Learning to train a neural network.\n",
        "\n",
        "No custom wrapper are used. Try to understand, how to use Tensorflow Federated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Training Performance ==\n",
            "{'mean_absolute_error': 5992.9106, 'mean_squared_error': 82627130.0, 'loss': 82899660.0, 'num_examples': 53500, 'num_batches': 420}\n",
            "== Testing Performance ==\n",
            "{'loss': 314921760.0, 'mean_squared_error': 314921760.0, 'mae': 13084.958984375, 'r2_score': -1.2825415134429932}\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "# =======\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "import tensorflow_federated as tff\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# parameter\n",
        "# =========\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "# a. model architecture\n",
        "def create_keras_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "      InputLayer(input_shape=[len(df.columns) - 2]),\n",
        "      Dense(40, activation='relu'),\n",
        "      Dense(40, activation='relu'),\n",
        "      Dense(20, activation='relu'),\n",
        "      Dense(1)\n",
        "  ])\n",
        "\n",
        "# b. training specifics\n",
        "NUM_ROUNDS = 5        # communication\n",
        "NUM_EPOCHS = 5        # local client rounds\n",
        "BATCH_SIZE = 128      # more training parameter\n",
        "SHUFFLE_BUFFER = 20\n",
        "PREFETCH_BUFFER = 5\n",
        "\n",
        "# Validation split\n",
        "# ================\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size = 0.2, random_state = SEED)\n",
        "\n",
        "# distribute data to clients \n",
        "# ==========================\n",
        "# (... and convert to tensor)\n",
        "\n",
        "train_data_fed = []\n",
        "for client in clients:\n",
        "\n",
        "  X_client = train_data.loc[\n",
        "    train_data[client_var] == client,  ~df.columns.isin([target, client_var])]\n",
        "  y_client = train_data.loc[train_data[client_var] == client,  target]\n",
        "\n",
        "  tensor_client = tf.data.Dataset.from_tensor_slices((\n",
        "    tf.convert_to_tensor(X_client),\n",
        "    tf.convert_to_tensor(y_client)))\n",
        "\n",
        "  train_data_fed.append(tensor_client)\n",
        "\n",
        "# convert model for FL\n",
        "# ====================\n",
        "def model_fn():\n",
        "  model = create_keras_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      model,\n",
        "      input_spec = (\n",
        "        tf.TensorSpec((\n",
        "          model.input.shape[0], \n",
        "          model.input.shape[1]\n",
        "          ), dtype = tf.float64),\n",
        "        tf.TensorSpec((None,), dtype = tf.float64)\n",
        "      ), loss = tf.keras.losses.MeanSquaredError(),\n",
        "      metrics =  [\n",
        "        tf.keras.metrics.MeanAbsoluteError()\n",
        "        , tf.keras.metrics.MeanSquaredError()\n",
        "        ]\n",
        "  )\n",
        "\n",
        "# Training\n",
        "# ========\n",
        "\n",
        "# prepare the data for training\n",
        "train_data_fed_proc = [\n",
        "  data.\n",
        "    repeat(NUM_EPOCHS).\n",
        "    shuffle(SHUFFLE_BUFFER, seed = SEED).\n",
        "    batch(BATCH_SIZE).\n",
        "    prefetch(PREFETCH_BUFFER)\n",
        "  for data in train_data_fed]\n",
        "\n",
        "# build a tff learning process\n",
        "process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "  model_fn,\n",
        "\tclient_optimizer_fn = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
        "\tserver_optimizer_fn = lambda: tf.optimizers.Adam(learning_rate = .05))\n",
        "\n",
        "# rem.: \n",
        "# 1. weighted FedAvg means weighted by the number of examples of each client\n",
        "# 2. because of the choice of server_optimizer, actually FedAdam is used (instead of FedAvg).\n",
        "# C.f.: https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg \n",
        "\n",
        "# initialize the tff process\n",
        "state = process.initialize()\n",
        "\n",
        "# apply training (each round the updated model is communicated to each client)\n",
        "hist = []\n",
        "\n",
        "for round in range(NUM_ROUNDS):\n",
        "  state, perf = process.next(state, train_data_fed_proc)\n",
        "  hist.append(dict(perf['client_work']['train'].items()))\n",
        "\n",
        "print(\"== Training Performance ==\")\n",
        "print(dict(perf['client_work']['train'].items()))\n",
        "\n",
        "# eval ???\n",
        "# ========\n",
        "\n",
        "# test\n",
        "# ====\n",
        "\n",
        "# Fetch a fresh model\n",
        "model = create_keras_model()\n",
        "model.compile(\n",
        "    loss = 'mean_squared_error',\n",
        "    metrics = ['mean_squared_error',\"mae\", r2_score],\n",
        "    run_eagerly = True)\n",
        "\n",
        "# Support the new model with the calculated weights\n",
        "weights = process.get_model_weights(state)\n",
        "weights.assign_weights_to(model)\n",
        "\n",
        "# Evaluate the model on the test data.\n",
        "perf_test = model.evaluate(\n",
        "    test_data.loc[:,~df.columns.isin([target, client_var])],\n",
        "    test_data[target],\n",
        "    verbose = 0)\n",
        "\n",
        "print(\"== Testing Performance ==\")\n",
        "print(dict(zip(model.metrics_names, perf_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc4ablTvdVZU"
      },
      "source": [
        "## 2. Minimal example with wrappers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section shows how to do the same operations from the first example using custom wrappers that we defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gaKQlHykd2rS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function prep_fed_train in module FLutils:\n",
            "\n",
            "prep_fed_train(X_train: pandas.core.frame.DataFrame, y_train: pandas.core.frame.DataFrame)\n",
            "    Converts training data to Tensor Object.\n",
            "    \n",
            "    See https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#preprocessing_the_input_data\n",
            "    \n",
            "    Args:\n",
            "        X_train (pd.DataFrame): Training features.\n",
            "        y_train (pd.DataFrame): Training target.\n",
            "    \n",
            "    Returns:\n",
            "        A `Tensor` based on `X_test`, `y_test`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import (\n",
        "  OrdinalEncoder, OneHotEncoder, MinMaxScaler)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "\n",
        "# import custom wrapper\n",
        "from FLutils import (\n",
        "    create_keras_model,    # construct a deep neural network (keras)\n",
        "    model_fn,              # convert keras model to tff.learning.models\n",
        "    prep_fed_train,        # convert training data to tensors for training w/ tensorflow\n",
        "    prep_fed_test,         # convert test data to tensors for testing w/ tensorflow (other format than training data)\n",
        "    train_fed              # train a keras model federated with distributed data\n",
        "    )\n",
        "\n",
        "# Compare:\n",
        "help(prep_fed_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0bCQlCTZd-eK"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "def keras_blueprint(compile = False, nfeatures = None):\n",
        "    if nfeatures == None: nfeatures = len(df.columns) - 2\n",
        "    # \"- 2\" because the target and a variable defining the clients are no features\n",
        "    return create_keras_model(\n",
        "        nfeatures = nfeatures,\n",
        "        units = [40, 40, 20],\n",
        "        activations = ['relu'] * 3,\n",
        "        compile = compile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8onfhAuUfR_Y",
        "outputId": "ce6fabec-5646-4403-89eb-5fee87f6c137"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<_TensorSliceDataset element_spec=(TensorSpec(shape=(5,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))>,\n",
              " <_TensorSliceDataset element_spec=(TensorSpec(shape=(5,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))>,\n",
              " <_TensorSliceDataset element_spec=(TensorSpec(shape=(5,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))>,\n",
              " <_TensorSliceDataset element_spec=(TensorSpec(shape=(5,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))>]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# distribute data to clients \n",
        "# ==========================\n",
        "# (... and convert to tensor)\n",
        "\n",
        "train_data, test_data = train_test_split(\n",
        "      df, test_size = 0.2, random_state = 42)\n",
        "\n",
        "train_data_fed = []\n",
        "test_data_fed = []\n",
        "\n",
        "for client in clients:\n",
        "  df_client = train_data[train_data[client_var] == client]\n",
        "  df_client_train = df_client\n",
        "  train_data_fed.append(\n",
        "      prep_fed_train(\n",
        "        df_client_train.loc[:,~ df_client_train.columns.isin([target, client_var])],\n",
        "        df_client_train[target]\n",
        "  ))\n",
        "train_data_fed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eBTyfRoDeUNW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====== ROUND  1 / 5 ======\n",
            "TRAIN: {'mean_absolute_error': 9253.215, 'mean_squared_error': 169215840.0, 'loss': 170328030.0, 'num_examples': 21400, 'num_batches': 169}\n",
            "====== ROUND  2 / 5 ======\n",
            "TRAIN: {'mean_absolute_error': 8794.255, 'mean_squared_error': 151058500.0, 'loss': 152083970.0, 'num_examples': 21400, 'num_batches': 169}\n",
            "====== ROUND  3 / 5 ======\n",
            "TRAIN: {'mean_absolute_error': 8512.211, 'mean_squared_error': 141342750.0, 'loss': 142294370.0, 'num_examples': 21400, 'num_batches': 169}\n",
            "====== ROUND  4 / 5 ======\n",
            "TRAIN: {'mean_absolute_error': 8276.477, 'mean_squared_error': 133320940.0, 'loss': 134199990.0, 'num_examples': 21400, 'num_batches': 169}\n",
            "====== ROUND  5 / 5 ======\n",
            "TRAIN: {'mean_absolute_error': 8035.832, 'mean_squared_error': 125608580.0, 'loss': 126420820.0, 'num_examples': 21400, 'num_batches': 169}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'mean_absolute_error': 8035.832,\n",
              " 'mean_squared_error': 125608580.0,\n",
              " 'loss': 126420820.0,\n",
              " 'num_examples': 21400,\n",
              " 'num_batches': 169}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training\n",
        "result =  train_fed(\n",
        "        model = model_fn(\n",
        "            keras_creator = keras_blueprint,\n",
        "            loss = tf.losses.MeanSquaredError()\n",
        "        ),\n",
        "\n",
        "        train_data = train_data_fed,\n",
        "        eval_data = None,\n",
        "        NUM_ROUNDS = 5,\n",
        "        NUM_EPOCHS = 20,\n",
        "        client_optimizer = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
        "        server_optimizer = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
        "        BATCH_SIZE = 128,\n",
        "        SHUFFLE_BUFFER = 20,\n",
        "        PREFETCH_BUFFER = 5,\n",
        "        SEED = 42,\n",
        "        verbose = True\n",
        "    )\n",
        "\n",
        "result['history'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buGFmUzYhEPj",
        "outputId": "1a4262e3-6c07-4b8b-a278-02dd407f0c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 49ms/step - loss: 316873056.0000 - mae: 12751.4023 - mean_squared_error: 316873056.0000 - r2_score: -1.1070\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'loss': 316873056.0,\n",
              " 'mae': 12751.40234375,\n",
              " 'mean_squared_error': 316873056.0,\n",
              " 'r2_score': -1.1070221662521362}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluation\n",
        "weights = result['process'].get_model_weights(result['state'])\n",
        "\n",
        "model = keras_blueprint(compile = True)\n",
        "weights.assign_weights_to(model)\n",
        "\n",
        "perf_test = model.evaluate(\n",
        "    test_data.loc[:,~test_data.columns.isin([target, client_var])], \n",
        "    test_data[target]\n",
        "    )\n",
        "dict(zip(model.metrics_names, perf_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An example for production."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:17<00:00,  5.86s/it]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import (\n",
        "  OrdinalEncoder, OneHotEncoder, MinMaxScaler)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# tensorflow (federated) and keras\n",
        "import tensorflow_federated as tff\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "# model selection\n",
        "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
        "\n",
        "# statusbar for loops\n",
        "import tqdm\n",
        "\n",
        "from FLutils import (\n",
        "    load_df,               # load data\n",
        "    create_keras_model,    # construct a deep neural network (keras)\n",
        "    model_fn,              # convert keras model to tff.learning.models\n",
        "    prep_fed_train,        # convert training data to tensors for learning with tensorflow\n",
        "    prep_fed_test,         # convert test data to tensors for testing with tensorflow (other format than training data)\n",
        "    train_model,           # train a keras model\n",
        "    train_fed              # train a keras model federated with distributed data\n",
        "    )\n",
        "\n",
        "\n",
        "# create evaluation splits\n",
        "# ========================\n",
        "\n",
        "nreps, nfolds = 1, 3\n",
        "evaluation = RepeatedStratifiedKFold(n_splits = nfolds, n_repeats = nreps, random_state = 42)\n",
        "\n",
        "\n",
        "# training budget\n",
        "# ===============\n",
        "\n",
        "n_epochs_fed =  5 # epochs for each client in one server iteration (federated training)\n",
        "n_rounds_fed =  5 # federated training rounds including distribution to the clients and aggregation of the results \n",
        "\n",
        "# define model architecture\n",
        "# =========================\n",
        "\n",
        "features_fed = df.columns[~df.columns.isin([target, client_var])]\n",
        "\n",
        "def keras_blueprint(compile = False, nfeatures = len(features_fed)):\n",
        "    if nfeatures == None: nfeatures = len(features)\n",
        "    \n",
        "    return create_keras_model(\n",
        "        nfeatures = nfeatures, \n",
        "        units = [40, 40, 20], \n",
        "        activations = ['relu'] * 3, \n",
        "        compile = compile)\n",
        "\n",
        "# Note 1: we do not compile the model yet. The loss, metrics, and optimizers are introduced later.\n",
        "#   S. https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#creating_a_model_with_keras\n",
        "# Note 2: this function has to generate a new instance of a keras_model \n",
        "#   to be useable for generating a federated learning process\n",
        "# Note 3: loss = mae -> overfitting?\n",
        "\n",
        "# experiment logging\n",
        "# ==================\n",
        "\n",
        "experiment_name = 'zz_tutorial'\n",
        "out_path = 'output/experiments'\n",
        "experiment_path = out_path + \"/\" + experiment_name + \"/\"\n",
        "if not os.path.exists(experiment_path + 'logs'): os.makedirs(experiment_path + 'logs')\n",
        "if not os.path.exists(experiment_path + 'models'): os.makedirs(experiment_path + 'models')\n",
        "if not os.path.exists(experiment_path + 'results'): os.makedirs(experiment_path + 'results')\n",
        "\n",
        "\n",
        "# compute train\n",
        "# =============\n",
        "\n",
        "results_fed = []\n",
        "\n",
        "eval_ind = 0 #nfolds*7#0\n",
        "for train, test in tqdm.tqdm(list(evaluation.split(df, df[client_var]))[:]):\n",
        "\n",
        "    # Logging\n",
        "    rep  = int(eval_ind / nfolds)\n",
        "    fold = int(eval_ind % nfolds)\n",
        "    eval_ind += 1\n",
        "    id = \"r\" + str(rep) + \"f\" + str(fold)\n",
        "    #print('======= rep %s - fold %s  =======' % (rep, fold))\n",
        "\n",
        "\n",
        "    # distribute train (and eval) data over the client and prep tensors.\n",
        "    train_data_fed = []\n",
        "    eval_data_fed  = []   \n",
        "    for client in clients:\n",
        "        outer_train_data_client = df[(df.index.isin(train)) & (df[client_var] == client)]\n",
        "        train_data_client, eval_data_client = train_test_split(outer_train_data_client, test_size = 0.1, random_state = 42)\n",
        "        \n",
        "        train_data_fed.append(\n",
        "            prep_fed_train(train_data_client[features_fed], train_data_client[target])) \n",
        "        eval_data_fed.append(\n",
        "            prep_fed_test(eval_data_client[features_fed], eval_data_client[target]))\n",
        "        \n",
        "    # train\n",
        "    #with tf.device('/device:gpu:0'): # possibly needed for colab\n",
        "    result =  train_fed(\n",
        "        model = model_fn(\n",
        "            keras_creator = keras_blueprint,\n",
        "            loss = tf.losses.MeanSquaredError()\n",
        "        ),\n",
        "        train_data = train_data_fed,\n",
        "        eval_data  = eval_data_fed,\n",
        "        NUM_ROUNDS = n_rounds_fed,\n",
        "        NUM_EPOCHS = n_epochs_fed,\n",
        "        client_optimizer = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
        "        server_optimizer = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
        "        BATCH_SIZE = 128,\n",
        "        SHUFFLE_BUFFER = 20,\n",
        "        PREFETCH_BUFFER = 5,\n",
        "        SEED = 42,\n",
        "        verbose = False\n",
        "    )\n",
        "    \n",
        "    # save history\n",
        "    pd.DataFrame(result['history']).to_csv(experiment_path + \"logs/\" + id + '_log.csv', sep = \";\")\n",
        "\n",
        "    # save model\n",
        "    model = keras_blueprint()\n",
        "    model_weights = result['process'].get_model_weights(result['state'])\n",
        "    model_weights.assign_weights_to(model)\n",
        "    model.save_weights(experiment_path + \"models/\" + id + '_weights.h5')\n",
        "    \n",
        "    # Note: load with e.g. \n",
        "    #   model = keras_blueprint(compile = True)\n",
        "    #   model.load_weights(experiment_path + 'models/r0f0_weights.h5')\n",
        "    #   model.weights\n",
        "\n",
        "    results_fed.append(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. Overview\n",
        "\n",
        "- Run the complete notebook.\n",
        "- Take a closer look on the minimal example 1 and try to understand the steps.\n",
        "- For what are the imported functions from FLutil.py used? Check using `help`.\n",
        "- What are changes in the section \"Production\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. Performance in training volume\n",
        "\n",
        "Change epochs (1, 5, 10, 25, 50) and rounds (5, 10, 25, 50), save the results and plot the test performance. Which hyperparameter has the higher impact on the performance - epochs or rounds?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C. Weighted or unweighted average?\n",
        "\n",
        "Use `build_unweighted_fed_avg` instead of `build_weighted_fed_avg` (or optionally custom weights). Are there changes in the result and its performance?\n",
        "\n",
        "Use the best epochs/rounds combination you have found in B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### D. New data (optional)\n",
        "\n",
        "Apply Federated Learning for a 2-class classification problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from pycaret.datasets import get_data\n",
        "#data = get_data('diabetes')\n",
        "#data\n",
        "\n",
        "# baselines here: https://pycaret.gitbook.io/docs/get-started/quickstart#classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Optional additional exercises.\n",
        "\n",
        "1. Try to optimize the layers and units of the model!\n",
        "1. Add cross validation to minimal example 1!\n",
        "1. Add training evaluation to minimal example 1!\n",
        "1. In minimal example 1, decrease the lines of code without changing functionality or generality!\n",
        "1. In minimal example 1: first distribute the data to each client, then generate a train-test split for each client! Rem.: Be careful with the randomization."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMA97ztPOzuuYe78Vft+zg/",
      "collapsed_sections": [
        "TTj_zg2rdax8",
        "fFexQMModRkl"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
